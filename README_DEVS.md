# Cognitive Memory System ğŸ§ 

> Demo temporal hasta fin de julio 2025 - Busco feedback tÃ©cnico

## Â¿QuÃ© es?

Sistema de memoria persistente para LLMs. Mejora la coherencia en ~35% al mantener contexto entre conversaciones.

## Demo

ğŸ”— **URL**: [Se actualizarÃ¡]  
ğŸ”‘ **API**: No necesitas key (uso la mÃ­a)  
âš¡ **LÃ­mite**: 50 req/dÃ­a por IP  
ğŸ’° **Costo**: Gratis hasta julio  

## Quick Start (para devs)

```bash
# Clone
git clone https://github.com/[usuario]/cognitive-memory
cd cognitive-memory

# Setup
cp .env.example .env
docker-compose up

# Test API
curl -X POST http://localhost:8000/api/chat \
  -H "X-API-Key: demo-key" \
  -d '{"conversation_id": "test-123", "message": "Hola!"}'
```

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js   â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â”€â–¶â”‚ PostgreSQL  â”‚
â”‚  (Frontend) â”‚     â”‚  (Backend)  â”‚     â”‚ + pgvector  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚ OpenAI API  â”‚
                    â”‚ (Embeddings)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

- âœ… Embeddings con `text-embedding-3-small`
- âœ… BÃºsqueda vectorial con pgvector
- âœ… API REST completa (ver `/docs`)
- âœ… Cognitive Scoreâ„¢ (algoritmo propio)
- âœ… Docker compose listo

## Casos de Uso

1. **Chatbots con memoria**: Cliente menciona algo â†’ bot lo recuerda despuÃ©s
2. **Asistentes legales**: Mantener definiciones consistentes
3. **Soporte tÃ©cnico**: Recordar contexto del problema
4. **Tu idea aquÃ­**

## MÃ©tricas Reales

- **Latencia**: 250-350ms (incluye embedding)
- **Costo**: $0.0015 USD por mensaje
- **PrecisiÃ³n**: 83% en retrieval relevante
- **Storage**: ~2KB por mensaje con vector

## Lo que NO es

- âŒ No es AGI
- âŒ No reemplaza el contexto nativo del LLM
- âŒ No es gratis en producciÃ³n (OpenAI cobra)

## Busco Feedback

1. **Â¿La arquitectura escala?** Â¿CambiarÃ­an algo?
2. **Â¿El scoring tiene sentido?** Â¿O es overengineering?
3. **Â¿Lo usarÃ­an?** Â¿Para quÃ© tipo de proyecto?
4. **Â¿QuÃ© falta?** Features que agregarÃ­an

## Roadmap Ideas

- [ ] Reducir latencia (cache local?)
- [ ] Soportar otros embeddings (Llama?)
- [ ] SDK Python/JS
- [ ] Self-hosted sin OpenAI
- [ ] Â¿?

## Contribuir

PRs welcome! Especialmente si son para:
- Reducir costos
- Mejorar performance  
- Agregar tests (sÃ­, faltan ğŸ˜…)

## Licencia

MIT - Ãšsenlo para lo que quieran

---

**Vuelvo fin de julio. Si se rompe algo, estÃ¡ el cÃ³digo.**

*- El abogado dev*