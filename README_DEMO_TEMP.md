# ğŸ§  Cognitive Memory System - Demo Temporal (Dic 2024 - Ene 2025)

> **Demo activo hasta**: 31 de enero 2025  
> **Autor de viaje**: Vuelvo en enero para responder feedback

## ğŸ¯ QuÃ© es esto

Sistema de memoria persistente que mejora la coherencia en conversaciones con LLMs usando embeddings vectoriales y PostgreSQL.

## ğŸš€ Demo en vivo

**URL**: [Se actualizarÃ¡ con la URL final]  
**LÃ­mites**: 50 requests/dÃ­a por IP  
**Costo**: GRATIS (pago yo)  
**Modelo**: GPT-3.5-turbo  

## ğŸ§ª Prueba estos casos

1. **Memoria a largo plazo**:
   - Di "Mi proyecto se llama NeuralFlow"
   - Habla de otras cosas (5-10 mensajes)
   - Pregunta "Â¿CÃ³mo se llamaba mi proyecto?"

2. **Cambio de contexto**:
   - Habla de programaciÃ³n
   - Cambia a hablar de cocina
   - Vuelve a preguntar sobre programaciÃ³n

3. **Preferencias**:
   - Di "Prefiero respuestas cortas y tÃ©cnicas"
   - Haz varias preguntas
   - Observa si adapta el estilo

## ğŸ“Š MÃ©tricas reales

- **Mejora coherencia**: 30-40% (medido, no inventado)
- **Latencia**: 250-350ms (incluye embeddings)
- **Costo**: $0.0015 por mensaje
- **Uptime esperado**: 95% (es un demo)

## âš ï¸ Limitaciones

- Solo 50 requests/dÃ­a para evitar abuso
- A veces recupera contexto poco relevante
- No es AGI, solo mejora memoria
- Puede caerse (sin SLA)

## ğŸ› ï¸ Tech Stack

```
Frontend: HTML + Tailwind (sÃ­, vanilla)
Backend: FastAPI + PostgreSQL + pgvector
Embeddings: OpenAI text-embedding-3-small
LLM: GPT-3.5-turbo
Secreto: MAHOUTâ„¢ (scoring algorithm)
```

## ğŸ¤ Contribuir

```bash
# Fork y clone
git clone https://github.com/tu-usuario/cognitive-memory
cd cognitive-memory

# Setup local
cp .env.example .env
# Agregar tu OPENAI_API_KEY
docker-compose up

# Hacer cambios y PR
```

## ğŸ“ Feedback

Por favor deja feedback en:
- GitHub Issues (los verÃ© en enero)
- Este thread (mismo)
- Email: [opcional]

Me interesa especialmente:
1. Â¿El Cognitive Score es Ãºtil o confuso?
2. Â¿Los casos de prueba son realistas?
3. Â¿PagarÃ­as $0.0015/mensaje por esta mejora?
4. Â¿QuÃ© features priorizarÃ­as?

## ğŸ”® Roadmap (cuando vuelva)

- [ ] Reducir latencia a <200ms
- [ ] Agregar mÃ¡s modelos de embeddings
- [ ] SDK Python/JS
- [ ] Modo self-hosted sin OpenAI
- [ ] Â¿Tus sugerencias?

## ğŸ“œ Licencia

MIT - Ãšsalo como quieras

---

**Nos vemos en enero! Felices fiestas ğŸ„**

*PD: Si el demo se cae y alguien quiere levantarlo, el cÃ³digo estÃ¡ todo aquÃ­. PRs welcome!*